#!/usr/bin/env python3
"""
Step 7: Quest VRå®æ—¶æ§åˆ¶æœºå™¨äºº - Pinchæ§åˆ¶ + å¹³æ»‘è¿åŠ¨ç‰ˆæœ¬

ä¸»è¦åŠŸèƒ½ï¼š
1. æ‰‹éƒ¨è¿½è¸ªï¼šä½¿ç”¨ pinchï¼ˆæåˆï¼‰æ§åˆ¶å¤¹çˆª
2. å¹³æ»‘æ»¤æ³¢ï¼šæŒ‡æ•°å¹³æ»‘ï¼Œè®©åŠ¨ä½œæ›´ä¸æ»‘
3. é€Ÿåº¦é™åˆ¶ï¼šå¯é€‰çš„é€Ÿåº¦é™åˆ¶åŠŸèƒ½
4. å¤´éƒ¨æ§åˆ¶ï¼šVRå¤´æ˜¾ä¿¯ä»°è§’å®æ—¶æ§åˆ¶æœºå™¨äººå¤´éƒ¨å§¿æ€
5. baselinkåæ ‡ç³»ï¼šä½ç½®æ§åˆ¶åŸºäºæœºå™¨äººè…°éƒ¨baselinkåæ ‡ç³»

æ§åˆ¶æ˜ å°„ï¼š
- åŒè‡‚ä½ç½®/å§¿æ€ï¼šè·ŸéšVRæ‰‹éƒ¨æˆ–æ‰‹æŸ„ä½ç½®ï¼ˆbaselinkåæ ‡ç³»ï¼‰
- å¤´éƒ¨å§¿æ€ï¼šè·ŸéšVRå¤´æ˜¾ä¿¯ä»°è§’ï¼ˆèŒƒå›´ï¼š-30Â° ~ 45Â°ï¼‰
- å¤¹çˆªï¼šPinchæ‰‹åŠ¿æˆ–æ‰‹æŸ„GripæŒ‰é’®

åæ ‡ç³»è¯´æ˜ï¼š
- å‚è€ƒåæ ‡ç³»ï¼šbase_linkï¼ˆæœºå™¨äººè…°éƒ¨ï¼‰
- Xè½´ï¼ˆçº¢è‰²ï¼‰ï¼šæœºå™¨äººå‰è¿›æ–¹å‘
- Yè½´ï¼ˆç»¿è‰²ï¼‰ï¼šæ­£æ–¹å‘å‘å·¦
- Zè½´ï¼ˆè“è‰²ï¼‰ï¼šç«–ç›´å‘ä¸Š

å¤¹çˆªæ§åˆ¶ï¼š
- Pinchå€¼èŒƒå›´: 0.0(é£ŸæŒ‡æ‹‡æŒ‡æç´§) ~ 0.1+(åˆ†å¼€)
- å¤¹çˆªæ˜ å°„: 
  * pinch <= 0.0 â†’ å¤¹çˆªå®Œå…¨é—­åˆ (0)
  * pinch >= 0.1 â†’ å¤¹çˆªå®Œå…¨å¼ å¼€ (1000)
  * ä¸­é—´å€¼çº¿æ€§æ’å€¼

å¹³æ»‘æ§åˆ¶å‚æ•°ï¼ˆRobotControllerç±»ï¼‰ï¼š
- enable_smoothing: æ˜¯å¦å¯ç”¨å¹³æ»‘ (é»˜è®¤True)
- smoothing_factor: å¹³æ»‘ç³»æ•° 0.0-1.0 (é»˜è®¤0.3ï¼Œæ¨è0.2-0.5)
  * è¶Šå° = å“åº”è¶Šå¿«ï¼Œè¶ŠæŠ–
  * è¶Šå¤§ = è¶Šå¹³æ»‘ï¼Œå»¶è¿Ÿè¶Šå¤§
- enable_velocity_limit: æ˜¯å¦é™é€Ÿ (é»˜è®¤False)
- max_velocity: æœ€å¤§é€Ÿåº¦ m/s (é»˜è®¤0.15)
- motion_scale: è¿åŠ¨ç¼©æ”¾ç³»æ•° (é»˜è®¤1.5ï¼Œæ¨è1.5-2.0)
  * æ”¾å¤§VRæ‰‹éƒ¨ç§»åŠ¨æ˜ å°„åˆ°æœºå™¨äººæœ«ç«¯çš„å¹…åº¦
  * è¶Šå¤§ = æœºå™¨äººç§»åŠ¨èŒƒå›´è¶Šå¤§

å¯è°ƒå‚æ•°ä½ç½®ï¼š
- PINCH_MAX: ç¬¬577è¡Œé™„è¿‘ï¼Œé»˜è®¤0.10
- smoothing_factor: ç¬¬86è¡Œï¼Œé»˜è®¤0.3
- max_velocity: ç¬¬83è¡Œï¼Œé»˜è®¤0.15
- motion_scale: ç¬¬71è¡Œï¼Œé»˜è®¤1.5ï¼ˆæˆ–åœ¨å¯åŠ¨æ—¶äº¤äº’å¼è®¾ç½®ï¼‰
"""

import numpy as np
import json
import time
import threading
import websocket
import uuid
from multiprocessing import shared_memory
from televuer.tv_wrapper import TeleVuerWrapper
import os
from pathlib import Path
import pickle
import sys

# å¯¼å…¥å›¾åƒå®¢æˆ·ç«¯
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
from image_service.image_client import ImageClient


class RobotController:
    """æœºå™¨äººæ§åˆ¶å™¨"""
    def __init__(self, robot_ip="10.192.1.2", enable_smoothing=True, enable_velocity_limit=False, motion_scale=1.5):
        self.url = f"ws://{robot_ip}:5000"
        self.ws = None
        self.accid = None
        self.connected = False
        self.ee_pose_response = None  # ç”¨äºæ¥æ”¶ä½å§¿æŸ¥è¯¢å“åº”
        
        # åŸºç¡€ä½å§¿ï¼ˆbaselinkåæ ‡ç³»ä¸‹çš„åˆå§‹ç»å¯¹ä½ç½®ï¼Œæ ‡å®šæ—¶è®¾ç½®ï¼‰
        self.base_left_pos = [0.0, 0.0, 0.0]
        self.base_left_quat = [0.0, 0.0, 0.0, 1.0]
        self.base_right_pos = [0.0, 0.0, 0.0]
        self.base_right_quat = [0.0, 0.0, 0.0, 1.0]
        
        # è¿åŠ¨ç¼©æ”¾ç³»æ•°ï¼ˆæ”¾å¤§VRæ‰‹éƒ¨ç§»åŠ¨ï¼‰
        self.motion_scale = motion_scale  # é»˜è®¤1.5å€ï¼Œå¯è°ƒæ•´ä¸º1.0-3.0
        
        # å·¥ä½œç©ºé—´é™åˆ¶ï¼ˆbaselinkåæ ‡ç³»ä¸‹çš„ç»å¯¹èŒƒå›´ï¼‰
        # æ ¹æ®æœºå™¨äººå®é™…æƒ…å†µè°ƒæ•´è¿™äº›å€¼
        # x: å‰åï¼ˆçº¢è‰²è½´ï¼Œæ­£æ–¹å‘å‘å‰ï¼‰
        # y: å·¦å³ï¼ˆç»¿è‰²è½´ï¼Œæ­£æ–¹å‘å‘å·¦ï¼‰
        # z: ä¸Šä¸‹ï¼ˆè“è‰²è½´ï¼Œæ­£æ–¹å‘å‘ä¸Šï¼‰
        self.workspace = {
            'x_min': -0.50, 'x_max': 0.80,   # å‰åèŒƒå›´
            'y_min': -0.80, 'y_max': 0.80,   # å·¦å³èŒƒå›´
            'z_min': 0.20, 'z_max': 1.50     # é«˜åº¦èŒƒå›´ï¼ˆè…°éƒ¨ä»¥ä¸Šï¼‰
        }
        
        # è¿åŠ¨æ§åˆ¶å‚æ•°
        self.enable_smoothing = enable_smoothing
        self.enable_velocity_limit = enable_velocity_limit
        self.max_velocity = 0.15  # m/s (ä»…åœ¨enable_velocity_limit=Trueæ—¶ç”Ÿæ•ˆ)
        
        # å¹³æ»‘æ»¤æ³¢å‚æ•° (0.0=æ— å¹³æ»‘, 1.0=å®Œå…¨å¹³æ»‘/ä¸åŠ¨)
        self.smoothing_factor = 0.3  # æ¨èèŒƒå›´: 0.2-0.5
        
        # å¹³æ»‘çŠ¶æ€å˜é‡
        self.smoothed_left_pos = None
        self.smoothed_right_pos = None
        self.smoothed_left_gripper = None
        self.smoothed_right_gripper = None
        self.last_time = None
        
        # å¤¹çˆªå‚æ•°
        self.gripper_speed = 500
        self.gripper_force = 300
        
    def on_message(self, ws, message):
        data = json.loads(message)
        if 'accid' in data and not self.accid:
            self.accid = data['accid']
            print(f"âœ… å·²è¿æ¥: {self.accid}")
        
        # å¤„ç†ä½å§¿æŸ¥è¯¢å“åº”
        if data.get('title') == 'response_get_ub_manip_ee_pose':
            self.ee_pose_response = data.get('data', {})
        
    def on_open(self, ws):
        self.connected = True
        
    def on_error(self, ws, error):
        print(f"âŒ WebSocketé”™è¯¯: {error}")
        
    def on_close(self, ws, close_status_code, close_msg):
        self.connected = False
        print("ğŸ”Œ WebSocketæ–­å¼€")
        
    def connect(self):
        """è¿æ¥æœºå™¨äºº"""
        self.ws = websocket.WebSocketApp(
            self.url,
            on_message=self.on_message,
            on_open=self.on_open,
            on_error=self.on_error,
            on_close=self.on_close
        )
        
        wst = threading.Thread(target=self.ws.run_forever, daemon=True)
        wst.start()
        
        timeout = 5
        start = time.time()
        while not self.connected and (time.time() - start) < timeout:
            time.sleep(0.1)
        
        if not self.connected:
            raise Exception("è¿æ¥è¶…æ—¶")
        
        time.sleep(1)
        return True
        
    def send_command(self, title, data=None):
        """å‘é€å‘½ä»¤"""
        msg = {
            "accid": self.accid,
            "title": title,
            "timestamp": int(time.time() * 1000),
            "guid": str(uuid.uuid4()).replace('-', ''),
            "data": data or {}
        }
        self.ws.send(json.dumps(msg))
    
    def get_current_ee_pose(self):
        """è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿ï¼ˆbaselinkåæ ‡ç³»ï¼‰"""
        # é‡ç½®å“åº”æ ‡å¿—
        self.ee_pose_response = None
        
        # å‘é€è¯·æ±‚
        self.send_command("request_get_ub_manip_ee_pose", {})
        
        # ç­‰å¾…å“åº”ï¼ˆæœ€å¤š2ç§’ï¼‰
        timeout = 2.0
        start = time.time()
        while self.ee_pose_response is None and (time.time() - start) < timeout:
            time.sleep(0.01)
        
        if self.ee_pose_response and self.ee_pose_response.get('result') == 'success':
            return {
                'left_hand_pos': self.ee_pose_response.get('left_hand_pos'),
                'left_hand_quat': self.ee_pose_response.get('left_hand_quat'),
                'right_hand_pos': self.ee_pose_response.get('right_hand_pos'),
                'right_hand_quat': self.ee_pose_response.get('right_hand_quat')
            }
        else:
            print("âš ï¸  è·å–æœºå™¨äººä½å§¿å¤±è´¥")
            return None
        
    def enter_damping(self):
        """è¿›å…¥é˜»å°¼æ¨¡å¼"""
        self.send_command("request_damping")
        time.sleep(2)
        
    def enter_prepare(self):
        """è¿›å…¥å‡†å¤‡æ¨¡å¼"""
        self.send_command("request_prepare")
        time.sleep(3)
        
    def set_ub_manip_mode(self, mode):
        """è®¾ç½®ä¸Šè‚¢æ“ä½œæ¨¡å¼"""
        self.send_command("request_set_ub_manip_mode", {"mode": mode})
        time.sleep(3 if mode in [0, 2] else 1)
        
    def set_pose(self, left_pos, left_quat, right_pos, right_quat, head_quat=None):
        """è®¾ç½®æœºå™¨äººä½å§¿"""
        data = {
            "head_quat": head_quat or [0.0, 0.0, 0.0, 1.0],
            "left_hand_pos": left_pos,
            "left_hand_quat": left_quat,
            "right_hand_pos": right_pos,
            "right_hand_quat": right_quat
        }
        self.send_command("request_set_ub_manip_ee_pose", data)
        
    def clip_to_workspace(self, pos):
        """é™åˆ¶ä½ç½®åˆ°å®‰å…¨å·¥ä½œç©ºé—´ï¼ˆbaselinkåæ ‡ç³»ä¸‹çš„ç»å¯¹ä½ç½®ï¼‰"""
        return [
            np.clip(pos[0], self.workspace['x_min'], self.workspace['x_max']),
            np.clip(pos[1], self.workspace['y_min'], self.workspace['y_max']),
            np.clip(pos[2], self.workspace['z_min'], self.workspace['z_max'])
        ]
    
    def smooth_position(self, target_pos, smoothed_pos):
        """æŒ‡æ•°å¹³æ»‘æ»¤æ³¢ - ä½ç½®"""
        if not self.enable_smoothing or smoothed_pos is None:
            return list(target_pos)  # ç¡®ä¿è¿”å›åˆ—è¡¨è€Œä¸æ˜¯numpyæ•°ç»„
        
        # æŒ‡æ•°å¹³æ»‘: output = alpha * new + (1-alpha) * old
        alpha = 1.0 - self.smoothing_factor
        smoothed = alpha * np.array(target_pos) + self.smoothing_factor * np.array(smoothed_pos)
        return smoothed.tolist()  # è½¬æ¢ä¸ºåˆ—è¡¨
    
    def smooth_gripper(self, target_gripper, smoothed_gripper):
        """æŒ‡æ•°å¹³æ»‘æ»¤æ³¢ - å¤¹çˆª"""
        if not self.enable_smoothing or smoothed_gripper is None:
            return target_gripper
        
        alpha = 1.0 - self.smoothing_factor * 0.7  # å¤¹çˆªå“åº”ç¨å¿«ä¸€äº›
        return alpha * target_gripper + self.smoothing_factor * 0.7 * smoothed_gripper
    
    def limit_velocity(self, target_pos, current_pos, dt):
        """é™åˆ¶é€Ÿåº¦"""
        if not self.enable_velocity_limit or current_pos is None or dt <= 0:
            return list(target_pos)  # ç¡®ä¿è¿”å›åˆ—è¡¨
        
        target = np.array(target_pos)
        current = np.array(current_pos)
        delta = target - current
        distance = np.linalg.norm(delta)
        
        max_distance = self.max_velocity * dt
        if distance > max_distance:
            # é™åˆ¶ç§»åŠ¨è·ç¦»
            delta = delta / distance * max_distance
            return (current + delta).tolist()
        
        return list(target_pos)  # ç¡®ä¿è¿”å›åˆ—è¡¨
    
    def set_gripper(self, left_opening=None, right_opening=None, apply_smoothing=True):
        """æ§åˆ¶å¤¹çˆªå¼€å£åº¦ï¼ˆå¸¦å¹³æ»‘ï¼‰"""
        # åº”ç”¨å¹³æ»‘
        if apply_smoothing:
            if left_opening is not None:
                left_opening = self.smooth_gripper(left_opening, self.smoothed_left_gripper)
                self.smoothed_left_gripper = left_opening
            
            if right_opening is not None:
                right_opening = self.smooth_gripper(right_opening, self.smoothed_right_gripper)
                self.smoothed_right_gripper = right_opening
        
        data = {}
        
        if left_opening is not None:
            left_opening = int(np.clip(left_opening, 0, 1000))
            data["left_opening"] = left_opening
            data["left_speed"] = self.gripper_speed
            data["left_force"] = self.gripper_force
            data["left_mode"] = 3
        
        if right_opening is not None:
            right_opening = int(np.clip(right_opening, 0, 1000))
            data["right_opening"] = right_opening
            data["right_speed"] = self.gripper_speed
            data["right_force"] = self.gripper_force
            data["right_mode"] = 3
        
        if data:
            self.send_command("request_set_claw_cmd", data)
    
    def set_pose_smooth(self, left_pos, left_quat, right_pos, right_quat, head_quat=None, dt=0.033):
        """è®¾ç½®æœºå™¨äººä½å§¿ï¼ˆå¸¦å¹³æ»‘å’Œé€Ÿåº¦é™åˆ¶ï¼‰"""
        # åº”ç”¨é€Ÿåº¦é™åˆ¶
        if self.enable_velocity_limit:
            left_pos = self.limit_velocity(left_pos, self.smoothed_left_pos, dt)
            right_pos = self.limit_velocity(right_pos, self.smoothed_right_pos, dt)
        
        # åº”ç”¨å¹³æ»‘
        if self.enable_smoothing:
            left_pos = self.smooth_position(left_pos, self.smoothed_left_pos)
            right_pos = self.smooth_position(right_pos, self.smoothed_right_pos)
            
            # æ›´æ–°å¹³æ»‘çŠ¶æ€
            self.smoothed_left_pos = left_pos
            self.smoothed_right_pos = right_pos
        
        # å‘é€æŒ‡ä»¤
        self.set_pose(left_pos, left_quat, right_pos, right_quat, head_quat)


def matrix_to_pos_quat(matrix):
    """ä»4x4çŸ©é˜µæå–ä½ç½®å’Œå››å…ƒæ•°"""
    pos = matrix[:3, 3].tolist()
    
    R = matrix[:3, :3]
    trace = np.trace(R)
    
    if trace > 0:
        s = 0.5 / np.sqrt(trace + 1.0)
        w = 0.25 / s
        x = (R[2, 1] - R[1, 2]) * s
        y = (R[0, 2] - R[2, 0]) * s
        z = (R[1, 0] - R[0, 1]) * s
    else:
        if R[0, 0] > R[1, 1] and R[0, 0] > R[2, 2]:
            s = 2.0 * np.sqrt(1.0 + R[0, 0] - R[1, 1] - R[2, 2])
            w = (R[2, 1] - R[1, 2]) / s
            x = 0.25 * s
            y = (R[0, 1] + R[1, 0]) / s
            z = (R[0, 2] + R[2, 0]) / s
        elif R[1, 1] > R[2, 2]:
            s = 2.0 * np.sqrt(1.0 + R[1, 1] - R[0, 0] - R[2, 2])
            w = (R[0, 2] - R[2, 0]) / s
            x = (R[0, 1] + R[1, 0]) / s
            y = 0.25 * s
            z = (R[1, 2] + R[2, 1]) / s
        else:
            s = 2.0 * np.sqrt(1.0 + R[2, 2] - R[0, 0] - R[1, 1])
            w = (R[1, 0] - R[0, 1]) / s
            x = (R[0, 2] + R[2, 0]) / s
            y = (R[1, 2] + R[2, 1]) / s
            z = 0.25 * s
    
    quat = [x, y, z, w]
    return pos, quat


def save_calibration(calib_left, calib_right, robot_base_left_pos, robot_base_right_pos, filename="vr_calibration.pkl"):
    """ä¿å­˜æ ‡å®šæ•°æ®"""
    calib_data = {
        'calib_left': calib_left,  # VRå·¦æ‰‹å‚è€ƒä½ç½®
        'calib_right': calib_right,  # VRå³æ‰‹å‚è€ƒä½ç½®
        'robot_base_left_pos': robot_base_left_pos,  # æœºå™¨äººå·¦æ‰‹åˆå§‹ç»å¯¹ä½ç½®ï¼ˆbaselinkåæ ‡ç³»ï¼‰
        'robot_base_right_pos': robot_base_right_pos,  # æœºå™¨äººå³æ‰‹åˆå§‹ç»å¯¹ä½ç½®ï¼ˆbaselinkåæ ‡ç³»ï¼‰
        'timestamp': time.time()
    }
    with open(filename, 'wb') as f:
        pickle.dump(calib_data, f)
    print(f"âœ… æ ‡å®šæ•°æ®å·²ä¿å­˜åˆ° {filename}")


def load_calibration(filename="vr_calibration.pkl"):
    """åŠ è½½æ ‡å®šæ•°æ®"""
    if not os.path.exists(filename):
        return None
    
    try:
        with open(filename, 'rb') as f:
            calib_data = pickle.load(f)
        
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(calib_data['timestamp']))
        print(f"\nğŸ“‚ æ‰¾åˆ°æ ‡å®šæ–‡ä»¶:")
        print(f"   ä¿å­˜æ—¶é—´: {timestamp}")
        print(f"   VRå·¦æ‰‹å‚è€ƒ: {calib_data['calib_left'][:3, 3]}")
        print(f"   VRå³æ‰‹å‚è€ƒ: {calib_data['calib_right'][:3, 3]}")
        
        robot_base_left_pos = calib_data.get('robot_base_left_pos', None)
        robot_base_right_pos = calib_data.get('robot_base_right_pos', None)
        
        if robot_base_left_pos:
            print(f"   æœºå™¨äººå·¦æ‰‹åˆå§‹ä½ç½®: {robot_base_left_pos}")
            print(f"   æœºå™¨äººå³æ‰‹åˆå§‹ä½ç½®: {robot_base_right_pos}")
        
        return calib_data['calib_left'], calib_data['calib_right'], robot_base_left_pos, robot_base_right_pos
    except Exception as e:
        print(f"âŒ åŠ è½½æ ‡å®šå¤±è´¥: {e}")
        return None


def calibrate_vr(tv_wrapper):
    """æ‰§è¡ŒVRæ ‡å®š"""
    print("ğŸ“Š å¼€å§‹é‡‡é›†æ ‡å®šæ•°æ®ï¼ˆä¿æŒåŒæ‰‹ä¸åŠ¨ï¼‰...")
    
    calibration_samples = []
    print("   æ ‡å®šä¸­", end='', flush=True)
    for i in range(30):
        tele_data = tv_wrapper.get_motion_state_data()
        calibration_samples.append({
            'left': tele_data.left_arm_pose.copy(),
            'right': tele_data.right_arm_pose.copy()
        })
        time.sleep(1/30)
        if (i+1) % 10 == 0:
            print(".", end='', flush=True)
    
    calib_left = np.mean([s['left'] for s in calibration_samples], axis=0)
    calib_right = np.mean([s['right'] for s in calibration_samples], axis=0)
    
    print(" å®Œæˆ!")
    print(f"\nâœ… æ ‡å®šæˆåŠŸ!")
    print(f"   å·¦æ‰‹å‚è€ƒä½ç½®: {calib_left[:3, 3]}")
    print(f"   å³æ‰‹å‚è€ƒä½ç½®: {calib_right[:3, 3]}")
    
    return calib_left, calib_right


def main():
    print("="*60)
    print("Step 7: Meta Quest VRå®æ—¶æ§åˆ¶ (Pinchç‰ˆæœ¬)")
    print("="*60)
    print("\nâš ï¸  å®‰å…¨æ£€æŸ¥:")
    print("â–¡ æœºå™¨äººå·²æ‚¬æŒ‚ï¼Œè„šç¦»åœ°â‰¥15cm")
    print("â–¡ SSLè¯ä¹¦å·²ç”Ÿæˆ (cert.pem, key.pem)")
    print("â–¡ Questå·²è¿æ¥åˆ°åŒä¸€WiFi")
    print("â–¡ é¥æ§å™¨åœ¨æ‰‹è¾¹")
    input("\nâœ… ç¡®è®¤åæŒ‰Enter...")
    
    # æ£€æŸ¥SSLè¯ä¹¦
    cert_file = Path("cert.pem")
    key_file = Path("key.pem")
    if not cert_file.exists() or not key_file.exists():
        print("\nâš ï¸  æœªæ‰¾åˆ°SSLè¯ä¹¦ï¼")
        print("è¿è¡Œ: python generate_ssl_cert.py")
        return
    
    print("\nåˆå§‹åŒ–VRæ¥å£...")
    # åˆ›å»ºè™šæ‹Ÿå›¾åƒå…±äº«å†…å­˜
    img_shape = (480, 640, 3)
    img_shm = shared_memory.SharedMemory(create=True, size=np.prod(img_shape) * np.uint8().itemsize)
    img_array = np.ndarray(img_shape, dtype=np.uint8, buffer=img_shm.buf)
    img_array[:] = 128  # ç°è‰²èƒŒæ™¯
    
    # è§†é¢‘å›ä¼ é€‰é¡¹
    print("\nğŸ“¹ æœºå™¨äººè§†é¢‘å›ä¼ :")
    print("1. å¯ç”¨è§†é¢‘å›ä¼  - åœ¨Questä¸­çœ‹åˆ°æœºå™¨äººæ‘„åƒå¤´ç”»é¢")
    print("2. ç¦ç”¨è§†é¢‘å›ä¼  - ä»…æ§åˆ¶ï¼Œä¸æ˜¾ç¤ºç”»é¢")
    video_choice = input("è¯·é€‰æ‹© [1/2ï¼Œé»˜è®¤1]: ").strip() or "1"
    enable_video = (video_choice == "1")
    
    robot_ip = "10.192.1.3"  # æœºå™¨äººIP (ä»testæ–‡ä»¶çœ‹æ˜¯10.192.1.3)
    zmq_port = 5556  # ZMQç«¯å£ (ä½¿ç”¨5556)
    image_client = None
    
    if enable_video:
        print(f"   å°†ä» {robot_ip}:{zmq_port} æ¥æ”¶è§†é¢‘æµ")
        print(f"   å›¾åƒå½¢çŠ¶: {img_shape}")
    
    # é€‰æ‹©æ¨¡å¼
    print("\né€‰æ‹©è¾“å…¥æ¨¡å¼:")
    print("1. æ‰‹æŸ„æ§åˆ¶å™¨ (controller)")
    print("2. æ‰‹éƒ¨è¿½è¸ª (hand tracking) - ä½¿ç”¨PINCHæ§åˆ¶å¤¹çˆª")
    mode = input("è¯·é€‰æ‹© [1/2]: ").strip()
    use_hand_tracking = (mode == "2")
    
    # åˆå§‹åŒ–TeleVuer
    tv_wrapper = TeleVuerWrapper(
        binocular=False,
        use_hand_tracking=use_hand_tracking,
        img_shape=img_shape,
        img_shm_name=img_shm.name,
        return_state_data=True,
        return_hand_rot_data=False,
        cert_file=str(cert_file.absolute()),
        key_file=str(key_file.absolute())
    )
    
    print(f"âœ… VRæœåŠ¡å·²å¯åŠ¨")
    print(f"   æ¨¡å¼: {'æ‰‹éƒ¨è¿½è¸ª(PINCH)' if use_hand_tracking else 'æ‰‹æŸ„æ§åˆ¶å™¨'}")
    print(f"\nğŸ“± åœ¨Questä¸­æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—®:")
    print(f"   https://vuer.ai?grid=False")
    input("\nç­‰å¾…Questè¿æ¥åæŒ‰Enterå¼€å§‹åˆå§‹åŒ–æœºå™¨äºº...")
    
    # å¯åŠ¨è§†é¢‘æ¥æ”¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if enable_video:
        print(f"\nğŸš€ å¯åŠ¨å›¾åƒå®¢æˆ·ç«¯...")
        print(f"   ç›®æ ‡æœåŠ¡å™¨: {robot_ip}:{zmq_port}")
        print(f"   å…±äº«å†…å­˜: {img_shm.name}")
        print(f"   å›¾åƒå½¢çŠ¶: {img_shape}")
        
        image_client = ImageClient(
            img_shape=img_shape,
            img_shm_name=img_shm.name,
            image_show=False,  # ä¸æ˜¾ç¤ºè°ƒè¯•çª—å£ï¼ˆåœ¨VRä¸­æ˜¾ç¤ºï¼‰
            server_address=robot_ip,
            port=zmq_port,
            enable_stats=False  # å…³é—­ç»Ÿè®¡ä¿¡æ¯æ‰“å°
        )
        image_client.start()
        print(f"âœ… å›¾åƒå®¢æˆ·ç«¯å·²å¯åŠ¨")
        print(f"ğŸ’¡ æç¤º: å›¾åƒä¼šè‡ªåŠ¨æ˜¾ç¤ºåœ¨Questçš„Vuerç•Œé¢ä¸­")
        print(f"   å¦‚æœæ²¡æœ‰ç”»é¢ï¼Œè¯·ç¡®ä¿æœºå™¨äººç«¯ZMQæœåŠ¡å™¨æ­£åœ¨è¿è¡Œ:")
        print(f"   ssh robot@{robot_ip}")
        print(f"   python ros2_to_zmq_bridge.py --camera camera0 --port {zmq_port} --stats")
        time.sleep(2)  # ç­‰å¾…è¿æ¥å»ºç«‹
    
    # å¹³æ»‘æ§åˆ¶é€‰é¡¹ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    print("\nğŸ›ï¸  è¿åŠ¨æ§åˆ¶é€‰é¡¹:")
    print("1. å¯ç”¨å¹³æ»‘æ»¤æ³¢ + é€Ÿåº¦é™åˆ¶ (æ¨è) - åŠ¨ä½œä¸æ»‘ç¨³å®š")
    print("2. ä»…å¯ç”¨å¹³æ»‘æ»¤æ³¢ - ä¸æ»‘ä½†ä¸é™é€Ÿ")
    print("3. åŸå§‹æ¨¡å¼ - æ— å¹³æ»‘æ— é™é€Ÿ")
    control_choice = input("è¯·é€‰æ‹© [1/2/3ï¼Œé»˜è®¤1]: ").strip() or "1"
    
    if control_choice == "1":
        enable_smoothing = True
        enable_velocity_limit = True
    elif control_choice == "2":
        enable_smoothing = True
        enable_velocity_limit = False
    else:
        enable_smoothing = False
        enable_velocity_limit = False
    
    # è¿åŠ¨ç¼©æ”¾ç³»æ•°è®¾ç½®
    print("\nğŸ”§ è¿åŠ¨ç¼©æ”¾ç³»æ•° (æ”¾å¤§VRæ‰‹éƒ¨ç§»åŠ¨):")
    print("   æ¨èå€¼: 1.5-2.0 (é»˜è®¤1.5)")
    print("   è¯´æ˜: ç³»æ•°è¶Šå¤§ï¼Œæœºå™¨äººæ‰‹è‡‚ç§»åŠ¨å¹…åº¦è¶Šå¤§")
    motion_scale_input = input("è¯·è¾“å…¥ç¼©æ”¾ç³»æ•° [é»˜è®¤1.5]: ").strip()
    try:
        motion_scale = float(motion_scale_input) if motion_scale_input else 1.5
        motion_scale = max(0.5, min(motion_scale, 3.0))  # é™åˆ¶åœ¨0.5-3.0èŒƒå›´
    except ValueError:
        motion_scale = 1.5
        print("   âš ï¸  è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼1.5")
    
    # è¿æ¥æœºå™¨äºº
    print("\nè¿æ¥æœºå™¨äºº...")
    robot = RobotController(
        enable_smoothing=enable_smoothing,
        enable_velocity_limit=enable_velocity_limit,
        motion_scale=motion_scale
    )
    robot.connect()
    
    if enable_smoothing:
        print(f"âœ… å¹³æ»‘æ»¤æ³¢å·²å¯ç”¨ (ç³»æ•°: {robot.smoothing_factor})")
    if enable_velocity_limit:
        print(f"âœ… é€Ÿåº¦é™åˆ¶å·²å¯ç”¨ (æœ€å¤§: {robot.max_velocity}m/s)")
    print(f"âœ… è¿åŠ¨ç¼©æ”¾å·²è®¾ç½® (ç³»æ•°: {robot.motion_scale}x)")
    
    # åˆå§‹åŒ–æœºå™¨äºº
    print("\nåˆå§‹åŒ–æœºå™¨äººæ¨¡å¼...")
    robot.enter_damping()
    print("âœ… é˜»å°¼æ¨¡å¼")
    time.sleep(1)
    
    robot.enter_prepare()
    print("âœ… å‡†å¤‡æ¨¡å¼")
    time.sleep(1)
    
    robot.set_ub_manip_mode(0)
    print("âœ… Mode 0 (åˆå§‹å§¿æ€)")
    time.sleep(2)
    
    robot.set_ub_manip_mode(1)
    print("âœ… Mode 1 (ç­‰å¾…æ§åˆ¶)")
    time.sleep(1)
    
    # æ ‡å®š
    print("\n"+"="*60)
    print("ğŸ¯ æ ‡å®šé˜¶æ®µ")
    print("="*60)
    
    print("\nâ±ï¸  å‡†å¤‡æ ‡å®šï¼Œå€’è®¡æ—¶...")
    print("   è¯·å°†åŒæ‰‹ç§»åŠ¨åˆ°èˆ’é€‚çš„èµ·å§‹ä½ç½®")
    for i in range(5, 0, -1):
        print(f"   {i}...", flush=True)
        time.sleep(1)
    print("   âœ… æ—¶é—´åˆ°!\n")
    
    # æ ‡å®šVRä½ç½®
    calib_left, calib_right = calibrate_vr(tv_wrapper)
    
    # è·å–æœºå™¨äººå½“å‰ä½ç½®ï¼ˆbaselinkåæ ‡ç³»ï¼‰
    print("\nğŸ¤– è·å–æœºå™¨äººå½“å‰ä½ç½®...")
    robot_pose = robot.get_current_ee_pose()
    
    if robot_pose is None:
        print("âŒ æ— æ³•è·å–æœºå™¨äººä½ç½®ï¼Œé€€å‡º")
        return
    
    robot_base_left_pos = robot_pose['left_hand_pos']
    robot_base_right_pos = robot_pose['right_hand_pos']
    
    # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
    if robot_base_left_pos is None or robot_base_right_pos is None:
        print("âŒ æœºå™¨äººä½ç½®æ•°æ®æ— æ•ˆï¼Œé€€å‡º")
        return
    
    print(f"âœ… æœºå™¨äººå·¦æ‰‹åˆå§‹ä½ç½®ï¼ˆbaselinkï¼‰: {robot_base_left_pos}")
    print(f"âœ… æœºå™¨äººå³æ‰‹åˆå§‹ä½ç½®ï¼ˆbaselinkï¼‰: {robot_base_right_pos}")
    
    # ä¿å­˜æ ‡å®šæ•°æ®
    save_calibration(calib_left, calib_right, robot_base_left_pos, robot_base_right_pos)
    
    # å°†åˆå§‹ä½ç½®ä¿å­˜åˆ°robotå¯¹è±¡
    robot.base_left_pos = robot_base_left_pos
    robot.base_right_pos = robot_base_right_pos
    
    # ä¸»æ§åˆ¶å¾ªç¯
    print("\n"+"="*60)
    print("ğŸ¤– å¼€å§‹æ§åˆ¶! (Ctrl+Cé€€å‡º)")
    print("="*60)
    print("ğŸ¯ æ§åˆ¶æ˜ å°„:")
    print("   â€¢ åŒè‡‚ï¼šè·ŸéšVRæ‰‹éƒ¨/æ‰‹æŸ„ä½ç½®å’Œå§¿æ€")
    print("   â€¢ å¤´éƒ¨ï¼šè·ŸéšVRå¤´æ˜¾ä¿¯ä»°è§’ï¼ˆ-30Â° ~ 45Â°ï¼‰")
    if use_hand_tracking:
        print("   â€¢ å¤¹çˆªï¼šé£ŸæŒ‡å’Œæ‹‡æŒ‡æåˆ(pinch)æ§åˆ¶å¼€åˆ")
    else:
        print("   â€¢ å¤¹çˆªï¼šæ¡æŠŠ(Grip)æŒ‰é’®æ§åˆ¶å¼€åˆ")
    print()
    
    try:
        control_rate = 30  # Hz
        dt = 1.0 / control_rate
        
        while True:
            loop_start = time.time()
            
            # è·å–VRæ•°æ®
            tele_data = tv_wrapper.get_motion_state_data()
            
            # è®¡ç®—VRç›¸å¯¹åç§»
            left_vr_offset = (tele_data.left_arm_pose[:3, 3] - calib_left[:3, 3]).tolist()
            right_vr_offset = (tele_data.right_arm_pose[:3, 3] - calib_right[:3, 3]).tolist()
            
            # åº”ç”¨è¿åŠ¨ç¼©æ”¾ç³»æ•°
            left_vr_offset_scaled = [x * robot.motion_scale for x in left_vr_offset]
            right_vr_offset_scaled = [x * robot.motion_scale for x in right_vr_offset]
            
            # è®¡ç®—baselinkåæ ‡ç³»ä¸‹çš„ç»å¯¹ä½ç½® = åˆå§‹ä½ç½® + ç¼©æ”¾åçš„VRåç§»
            left_target_pos = [
                robot.base_left_pos[0] + left_vr_offset_scaled[0],
                robot.base_left_pos[1] + left_vr_offset_scaled[1],
                robot.base_left_pos[2] + left_vr_offset_scaled[2]
            ]
            right_target_pos = [
                robot.base_right_pos[0] + right_vr_offset_scaled[0],
                robot.base_right_pos[1] + right_vr_offset_scaled[1],
                robot.base_right_pos[2] + right_vr_offset_scaled[2]
            ]
            
            # é™åˆ¶åˆ°å®‰å…¨å·¥ä½œç©ºé—´
            left_pos_safe = robot.clip_to_workspace(left_target_pos)
            right_pos_safe = robot.clip_to_workspace(right_target_pos)
            
            # æå–å››å…ƒæ•°ï¼ˆåŒè‡‚å’Œå¤´éƒ¨ï¼‰
            _, left_quat = matrix_to_pos_quat(tele_data.left_arm_pose)
            _, right_quat = matrix_to_pos_quat(tele_data.right_arm_pose)
            _, head_quat = matrix_to_pos_quat(tele_data.head_pose)
            
            # å‘é€åˆ°æœºå™¨äººï¼ˆå¸¦å¹³æ»‘å’Œé€Ÿåº¦é™åˆ¶ï¼‰
            robot.set_pose_smooth(
                left_pos=left_pos_safe,
                left_quat=left_quat,
                right_pos=right_pos_safe,
                right_quat=right_quat,
                head_quat=head_quat,
                dt=dt
            )
            
            # å¤¹çˆªæ§åˆ¶
            if use_hand_tracking:
                # *** ä½¿ç”¨PINCHè€Œä¸æ˜¯SQUEEZE ***
                # æ ¹æ®å®é™…æµ‹è¯•ï¼Œæœ‰æ•ˆpinchèŒƒå›´: 0.0(æç´§) ~ 0.1(åˆ†å¼€)
                # æ˜ å°„: pinch=0.0 -> å¤¹çˆª=0(é—­åˆ), pinch=0.1 -> å¤¹çˆª=1000(å¼ å¼€)
                if tele_data.left_pinch_value is not None and tele_data.right_pinch_value is not None:
                    # å®šä¹‰pinchçš„æœ‰æ•ˆæ§åˆ¶èŒƒå›´
                    PINCH_MAX = 0.10  # åˆ†å¼€åˆ°è¿™ä¸ªå€¼æ—¶ï¼Œå¤¹çˆªå®Œå…¨å¼ å¼€
                    PINCH_MIN = 0.00  # æç´§åˆ°è¿™ä¸ªå€¼æ—¶ï¼Œå¤¹çˆªå®Œå…¨é—­åˆ
                    
                    # pinch_valueä»TeleVueræ¥çš„æ˜¯ç™¾åˆ†æ¯”ï¼Œéœ€è¦è½¬æ¢ä¸º0-1
                    left_pinch = tele_data.left_pinch_value / 100.0
                    right_pinch = tele_data.right_pinch_value / 100.0
                    
                    # å½’ä¸€åŒ–åˆ°0-1ï¼Œè¶…å‡ºèŒƒå›´ä¼šè¢«clip
                    # pinch=0.0 -> norm=0.0 -> gripper=0 (é—­åˆ)
                    # pinch=0.1 -> norm=1.0 -> gripper=1000 (å¼ å¼€)
                    left_pinch_norm = np.clip(left_pinch / PINCH_MAX, 0.0, 1.0)
                    right_pinch_norm = np.clip(right_pinch / PINCH_MAX, 0.0, 1.0)
                    
                    # æ˜ å°„åˆ°å¤¹çˆªå¼€å£åº¦ [0, 1000]
                    left_gripper = int(left_pinch_norm * 1000)
                    right_gripper = int(right_pinch_norm * 1000)
                    
                    robot.set_gripper(left_opening=left_gripper, right_opening=right_gripper)
            else:
                # æ‰‹æŸ„æ¨¡å¼ï¼šä½¿ç”¨æ¡æŠŠæŒ‰é’®
                if tele_data.tele_state:
                    left_squeeze = tele_data.tele_state.left_squeeze_ctrl_value
                    right_squeeze = tele_data.tele_state.right_squeeze_ctrl_value
                    left_gripper = int((1.0 - left_squeeze) * 1000)
                    right_gripper = int((1.0 - right_squeeze) * 1000)
                    robot.set_gripper(left_opening=left_gripper, right_opening=right_gripper)
            
            # æ‰“å°çŠ¶æ€
            if int(time.time() * 3) % 3 == 0:
                gripper_info = ""
                if use_hand_tracking:
                    if tele_data.left_pinch_value is not None:
                        PINCH_MAX = 0.10  # ä¸æ§åˆ¶é€»è¾‘ä¿æŒä¸€è‡´
                        left_p_raw = tele_data.left_pinch_value / 100.0
                        right_p_raw = tele_data.right_pinch_value / 100.0
                        left_p_norm = np.clip(left_p_raw / PINCH_MAX, 0.0, 1.0)
                        right_p_norm = np.clip(right_p_raw / PINCH_MAX, 0.0, 1.0)
                        left_g = int(left_p_norm * 1000)
                        right_g = int(right_p_norm * 1000)
                        gripper_info = f"  å¤¹çˆª L:{left_g:4d} R:{right_g:4d} [Pinch: L:{left_p_raw:.3f} R:{right_p_raw:.3f}]"
                elif tele_data.tele_state:
                    left_sq = tele_data.tele_state.left_squeeze_ctrl_value
                    right_sq = tele_data.tele_state.right_squeeze_ctrl_value
                    left_g = int((1.0 - left_sq) * 1000)
                    right_g = int((1.0 - right_sq) * 1000)
                    gripper_info = f"  å¤¹çˆª L:{left_g:4d} R:{right_g:4d} [Grip: L:{left_sq:.2f} R:{right_sq:.2f}]"
                
                print(f"\rå·¦æ‰‹: [{left_pos_safe[0]:+.3f}, {left_pos_safe[1]:+.3f}, {left_pos_safe[2]:+.3f}]  "
                      f"å³æ‰‹: [{right_pos_safe[0]:+.3f}, {right_pos_safe[1]:+.3f}, {right_pos_safe[2]:+.3f}]"
                      f"{gripper_info}", end='')
            
            # æ§åˆ¶é¢‘ç‡
            elapsed = time.time() - loop_start
            if elapsed < dt:
                time.sleep(dt - elapsed)
                
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
    finally:
        print("\né€€å‡ºæ§åˆ¶æ¨¡å¼...")
        
        # å…ˆåœæ­¢è§†é¢‘æ¥æ”¶ï¼Œé¿å…å¹²æ‰°
        if image_client:
            print("ğŸ“· åœæ­¢å›¾åƒå®¢æˆ·ç«¯...")
            try:
                image_client.close()
            except Exception as e:
                # å¿½ç•¥å…³é—­æ—¶çš„ZMQé”™è¯¯ï¼ˆæ­£å¸¸ç°è±¡ï¼‰
                pass
        
        robot.set_ub_manip_mode(2)
        print("âœ… Mode 2 (é€€å‡º)")
        time.sleep(2)
        
        robot.enter_damping()
        print("âœ… é˜»å°¼æ¨¡å¼")
        
        # æ¸…ç†å…±äº«å†…å­˜
        try:
            img_shm.close()
            img_shm.unlink()
        except Exception:
            pass
        
        print("ğŸ‘‹ é€€å‡ºå®Œæˆ")


if __name__ == "__main__":
    main()

