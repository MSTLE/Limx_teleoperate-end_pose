#!/usr/bin/env python3
"""
Step 7: Quest VRå®æ—¶æ§åˆ¶æœºå™¨äºº (ä½¿ç”¨åŸç‰ˆTeleVuerWrapper)

å®‰å…¨è¯´æ˜:
1. æœºå™¨äººå¿…é¡»æ‚¬æŒ‚ï¼Œè„šç¦»åœ°â‰¥15cm
2. æ§åˆ¶èŒƒå›´é™åˆ¶åœ¨Â±20cmä»¥å†…
3. é¥æ§å™¨åœ¨æ‰‹è¾¹éšæ—¶å¯æŒ‰L2+Xæ€¥åœ
4. ä½¿ç”¨ç›¸å¯¹åæ ‡ç³»ï¼Œ[0,0,0]ä¸ºé›¶åç§»ï¼Œç›¸å¯¹äºMode 1åˆå§‹å§¿æ€
"""

import numpy as np
import json
import time
import threading
import websocket
import uuid
from multiprocessing import shared_memory
from televuer.tv_wrapper import TeleVuerWrapper
import os
from pathlib import Path
import pickle


class RobotController:
    """æœºå™¨äººæ§åˆ¶å™¨"""
    def __init__(self, robot_ip="10.192.1.2"):
        self.url = f"ws://{robot_ip}:5000"
        self.ws = None
        self.accid = None
        self.connected = False
        
        # âš ï¸ é‡è¦ï¼šAPIä½¿ç”¨ç›¸å¯¹åæ ‡ç³»ï¼
        # [0.0, 0.0, 0.0] = ç›¸å¯¹äºMode 0åˆå§‹å§¿æ€ï¼Œé›¶åç§»
        self.base_left_pos = [0.0, 0.0, 0.0]
        self.base_left_quat = [0.0, 0.0, 0.0, 1.0]
        self.base_right_pos = [0.0, 0.0, 0.0]
        self.base_right_quat = [0.0, 0.0, 0.0, 1.0]
        
        # å·¥ä½œç©ºé—´é™åˆ¶ï¼ˆç›¸å¯¹åç§»çš„æœ€å¤§å€¼ï¼‰
        self.workspace = {
            'x_min': -0.10, 'x_max': 0.20,
            'y_min': -0.15, 'y_max': 0.15,
            'z_min': -0.15, 'z_max': 0.20
        }
        
        self.max_velocity = 0.15  # m/s
        
    def on_message(self, ws, message):
        data = json.loads(message)
        if 'accid' in data and not self.accid:
            self.accid = data['accid']
            print(f"âœ… å·²è¿æ¥: {self.accid}")
        
    def on_open(self, ws):
        self.connected = True
        
    def on_error(self, ws, error):
        print(f"âŒ WebSocketé”™è¯¯: {error}")
        
    def on_close(self, ws, close_status_code, close_msg):
        self.connected = False
        print("ğŸ”Œ WebSocketæ–­å¼€")
        
    def connect(self):
        """è¿æ¥æœºå™¨äºº"""
        self.ws = websocket.WebSocketApp(
            self.url,
            on_message=self.on_message,
            on_open=self.on_open,
            on_error=self.on_error,
            on_close=self.on_close
        )
        
        wst = threading.Thread(target=self.ws.run_forever, daemon=True)
        wst.start()
        
        timeout = 5
        start = time.time()
        while not self.connected and (time.time() - start) < timeout:
            time.sleep(0.1)
        
        if not self.connected:
            raise Exception("è¿æ¥è¶…æ—¶")
            
        # ç­‰å¾…accid
        time.sleep(1)
        return True
        
    def send_command(self, title, data=None):
        """å‘é€å‘½ä»¤"""
        msg = {
            "accid": self.accid,
            "title": title,
            "timestamp": int(time.time() * 1000),
            "guid": str(uuid.uuid4()).replace('-', ''),
            "data": data or {}
        }
        self.ws.send(json.dumps(msg))
        
    def enter_damping(self):
        """è¿›å…¥é˜»å°¼æ¨¡å¼"""
        self.send_command("request_damping")
        time.sleep(2)
        
    def enter_prepare(self):
        """è¿›å…¥å‡†å¤‡æ¨¡å¼"""
        self.send_command("request_prepare")
        time.sleep(3)
        
    def set_ub_manip_mode(self, mode):
        """è®¾ç½®ä¸Šè‚¢æ“ä½œæ¨¡å¼ (0/1/2)"""
        self.send_command("request_set_ub_manip_mode", {"mode": mode})
        time.sleep(3 if mode in [0, 2] else 1)
        
    def set_pose(self, left_pos, left_quat, right_pos, right_quat, head_quat=None):
        """è®¾ç½®æœºå™¨äººä½å§¿ï¼ˆç›¸å¯¹åæ ‡ï¼‰"""
        data = {
            "head_quat": head_quat or [0.0, 0.0, 0.0, 1.0],
            "left_hand_pos": left_pos,
            "left_hand_quat": left_quat,
            "right_hand_pos": right_pos,
            "right_hand_quat": right_quat
        }
        self.send_command("request_set_ub_manip_ee_pose", data)
        
    def clip_to_workspace(self, offset):
        """é™åˆ¶åç§»é‡åˆ°å®‰å…¨èŒƒå›´"""
        return [
            np.clip(offset[0], self.workspace['x_min'], self.workspace['x_max']),
            np.clip(offset[1], self.workspace['y_min'], self.workspace['y_max']),
            np.clip(offset[2], self.workspace['z_min'], self.workspace['z_max'])
        ]


def matrix_to_pos_quat(matrix):
    """ä»4x4çŸ©é˜µæå–ä½ç½®å’Œå››å…ƒæ•°"""
    pos = matrix[:3, 3].tolist()
    
    # æ—‹è½¬çŸ©é˜µè½¬å››å…ƒæ•°
    R = matrix[:3, :3]
    trace = np.trace(R)
    
    if trace > 0:
        s = 0.5 / np.sqrt(trace + 1.0)
        w = 0.25 / s
        x = (R[2, 1] - R[1, 2]) * s
        y = (R[0, 2] - R[2, 0]) * s
        z = (R[1, 0] - R[0, 1]) * s
    else:
        if R[0, 0] > R[1, 1] and R[0, 0] > R[2, 2]:
            s = 2.0 * np.sqrt(1.0 + R[0, 0] - R[1, 1] - R[2, 2])
            w = (R[2, 1] - R[1, 2]) / s
            x = 0.25 * s
            y = (R[0, 1] + R[1, 0]) / s
            z = (R[0, 2] + R[2, 0]) / s
        elif R[1, 1] > R[2, 2]:
            s = 2.0 * np.sqrt(1.0 + R[1, 1] - R[0, 0] - R[2, 2])
            w = (R[0, 2] - R[2, 0]) / s
            x = (R[0, 1] + R[1, 0]) / s
            y = 0.25 * s
            z = (R[1, 2] + R[2, 1]) / s
        else:
            s = 2.0 * np.sqrt(1.0 + R[2, 2] - R[0, 0] - R[1, 1])
            w = (R[1, 0] - R[0, 1]) / s
            x = (R[0, 2] + R[2, 0]) / s
            y = (R[1, 2] + R[2, 1]) / s
            z = 0.25 * s
    
    quat = [x, y, z, w]
    return pos, quat


def save_calibration(calib_left, calib_right, filename="vr_calibration.pkl"):
    """ä¿å­˜æ ‡å®šæ•°æ®"""
    calib_data = {
        'calib_left': calib_left,
        'calib_right': calib_right,
        'timestamp': time.time()
    }
    with open(filename, 'wb') as f:
        pickle.dump(calib_data, f)
    print(f"âœ… æ ‡å®šæ•°æ®å·²ä¿å­˜åˆ° {filename}")


def load_calibration(filename="vr_calibration.pkl"):
    """åŠ è½½æ ‡å®šæ•°æ®"""
    if not os.path.exists(filename):
        return None
    
    try:
        with open(filename, 'rb') as f:
            calib_data = pickle.load(f)
        
        # æ˜¾ç¤ºæ ‡å®šä¿¡æ¯
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(calib_data['timestamp']))
        print(f"\nğŸ“‚ æ‰¾åˆ°æ ‡å®šæ–‡ä»¶:")
        print(f"   ä¿å­˜æ—¶é—´: {timestamp}")
        print(f"   å·¦æ‰‹å‚è€ƒ: {calib_data['calib_left'][:3, 3]}")
        print(f"   å³æ‰‹å‚è€ƒ: {calib_data['calib_right'][:3, 3]}")
        
        return calib_data['calib_left'], calib_data['calib_right']
    except Exception as e:
        print(f"âŒ åŠ è½½æ ‡å®šå¤±è´¥: {e}")
        return None


def calibrate_vr(tv_wrapper):
    """æ‰§è¡ŒVRæ ‡å®š"""
    print("ğŸ“Š å¼€å§‹é‡‡é›†æ ‡å®šæ•°æ®ï¼ˆä¿æŒåŒæ‰‹ä¸åŠ¨ï¼‰...")
    
    calibration_samples = []
    print("   æ ‡å®šä¸­", end='', flush=True)
    for i in range(30):  # 1ç§’é‡‡æ ·30æ¬¡
        tele_data = tv_wrapper.get_motion_state_data()
        calibration_samples.append({
            'left': tele_data.left_arm_pose.copy(),
            'right': tele_data.right_arm_pose.copy()
        })
        time.sleep(1/30)
        if (i+1) % 10 == 0:
            print(".", end='', flush=True)
    
    # è®¡ç®—æ ‡å®šåç§»ï¼ˆå¹³å‡å€¼ï¼‰
    calib_left = np.mean([s['left'] for s in calibration_samples], axis=0)
    calib_right = np.mean([s['right'] for s in calibration_samples], axis=0)
    
    print(" å®Œæˆ!")
    print(f"\nâœ… æ ‡å®šæˆåŠŸ!")
    print(f"   å·¦æ‰‹å‚è€ƒä½ç½®: {calib_left[:3, 3]}")
    print(f"   å³æ‰‹å‚è€ƒä½ç½®: {calib_right[:3, 3]}")
    
    return calib_left, calib_right


def main():
    print("="*60)
    print("Step 7: Meta Quest VRå®æ—¶æ§åˆ¶")
    print("="*60)
    print("\nâš ï¸  å®‰å…¨æ£€æŸ¥:")
    print("â–¡ æœºå™¨äººå·²æ‚¬æŒ‚ï¼Œè„šç¦»åœ°â‰¥15cm")
    print("â–¡ SSLè¯ä¹¦å·²ç”Ÿæˆ (cert.pem, key.pem)")
    print("â–¡ Questå·²è¿æ¥åˆ°åŒä¸€WiFi")
    print("â–¡ é¥æ§å™¨åœ¨æ‰‹è¾¹")
    input("\nâœ… ç¡®è®¤åæŒ‰Enter...")
    
    # æ£€æŸ¥SSLè¯ä¹¦
    cert_file = Path("cert.pem")
    key_file = Path("key.pem")
    if not cert_file.exists() or not key_file.exists():
        print("\nâš ï¸  æœªæ‰¾åˆ°SSLè¯ä¹¦ï¼")
        print("è¿è¡Œ: python generate_ssl_cert.py")
        return
    
    print("\nåˆå§‹åŒ–VRæ¥å£...")
    # åˆ›å»ºè™šæ‹Ÿå›¾åƒå…±äº«å†…å­˜ï¼ˆTeleVuerWrapperéœ€è¦ï¼‰
    img_shape = (480, 640, 3)
    img_shm = shared_memory.SharedMemory(create=True, size=np.prod(img_shape) * np.uint8().itemsize)
    img_array = np.ndarray(img_shape, dtype=np.uint8, buffer=img_shm.buf)
    img_array[:] = 128  # ç°è‰²èƒŒæ™¯
    
    # é€‰æ‹©æ¨¡å¼
    print("\né€‰æ‹©è¾“å…¥æ¨¡å¼:")
    print("1. æ‰‹æŸ„æ§åˆ¶å™¨ (controller)")
    print("2. æ‰‹éƒ¨è¿½è¸ª (hand tracking)")
    mode = input("è¯·é€‰æ‹© [1/2]: ").strip()
    use_hand_tracking = (mode == "2")
    
    # åˆå§‹åŒ–TeleVuer
    tv_wrapper = TeleVuerWrapper(
        binocular=False,
        use_hand_tracking=use_hand_tracking,
        img_shape=img_shape,
        img_shm_name=img_shm.name,
        return_state_data=True,
        return_hand_rot_data=False,
        cert_file=str(cert_file.absolute()),
        key_file=str(key_file.absolute())
    )
    
    print(f"âœ… VRæœåŠ¡å·²å¯åŠ¨")
    print(f"   æ¨¡å¼: {'æ‰‹éƒ¨è¿½è¸ª' if use_hand_tracking else 'æ‰‹æŸ„æ§åˆ¶å™¨'}")
    print(f"\nğŸ“± åœ¨Questä¸­æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—®:")
    print(f"   https://vuer.ai?grid=False")
    print(f"   (æˆ–è€…æ˜¾ç¤ºçš„å…·ä½“åœ°å€)")
    input("\nç­‰å¾…Questè¿æ¥åæŒ‰Enterå¼€å§‹åˆå§‹åŒ–æœºå™¨äºº...")
    
    # è¿æ¥æœºå™¨äºº
    print("\nè¿æ¥æœºå™¨äºº...")
    robot = RobotController()
    robot.connect()
    
    # åˆå§‹åŒ–æœºå™¨äºº
    print("\nåˆå§‹åŒ–æœºå™¨äººæ¨¡å¼...")
    robot.enter_damping()
    print("âœ… é˜»å°¼æ¨¡å¼")
    time.sleep(1)
    
    robot.enter_prepare()
    print("âœ… å‡†å¤‡æ¨¡å¼")
    time.sleep(1)
    
    robot.set_ub_manip_mode(0)
    print("âœ… Mode 0 (åˆå§‹å§¿æ€)")
    time.sleep(2)
    
    robot.set_ub_manip_mode(1)
    print("âœ… Mode 1 (ç­‰å¾…æ§åˆ¶)")
    time.sleep(1)
    
    # æ ‡å®šVRåæ ‡ç³»ï¼ˆæ¯æ¬¡éƒ½é‡æ–°æ ‡å®šï¼‰
    print("\n"+"="*60)
    print("ğŸ¯ æ ‡å®šé˜¶æ®µ")
    print("="*60)
    
    # 5ç§’å€’è®¡æ—¶å‡†å¤‡
    print("\nâ±ï¸  å‡†å¤‡æ ‡å®šï¼Œå€’è®¡æ—¶...")
    print("   è¯·å°†åŒæ‰‹ç§»åŠ¨åˆ°èˆ’é€‚çš„èµ·å§‹ä½ç½®")
    for i in range(5, 0, -1):
        print(f"   {i}...", flush=True)
        time.sleep(1)
    print("   âœ… æ—¶é—´åˆ°!\n")
    
    # æ‰§è¡Œæ ‡å®š
    calib_left, calib_right = calibrate_vr(tv_wrapper)
    save_calibration(calib_left, calib_right)
    
    # ä¸»æ§åˆ¶å¾ªç¯
    print("\n"+"="*60)
    print("ğŸ¤– å¼€å§‹æ§åˆ¶! (Ctrl+Cé€€å‡º)")
    print("="*60)
    print()
    
    try:
        control_rate = 30  # Hz
        dt = 1.0 / control_rate
        
        while True:
            loop_start = time.time()
            
            # è·å–VRæ•°æ®
            tele_data = tv_wrapper.get_motion_state_data()
            
            # è®¡ç®—ç›¸å¯¹åç§»
            left_offset = (tele_data.left_arm_pose[:3, 3] - calib_left[:3, 3]).tolist()
            right_offset = (tele_data.right_arm_pose[:3, 3] - calib_right[:3, 3]).tolist()
            
            # é™åˆ¶åˆ°å®‰å…¨èŒƒå›´
            left_offset_safe = robot.clip_to_workspace(left_offset)
            right_offset_safe = robot.clip_to_workspace(right_offset)
            
            # æå–å››å…ƒæ•°
            _, left_quat = matrix_to_pos_quat(tele_data.left_arm_pose)
            _, right_quat = matrix_to_pos_quat(tele_data.right_arm_pose)
            
            # å‘é€åˆ°æœºå™¨äººï¼ˆç›¸å¯¹åæ ‡ï¼‰
            robot.set_pose(
                left_pos=left_offset_safe,
                left_quat=left_quat,
                right_pos=right_offset_safe,
                right_quat=right_quat
            )
            
            # æ‰“å°çŠ¶æ€ï¼ˆæ¯ç§’1æ¬¡ï¼‰
            if int(time.time() * 1) % 1 == 0:
                print(f"\rå·¦: [{left_offset_safe[0]:+.3f}, {left_offset_safe[1]:+.3f}, {left_offset_safe[2]:+.3f}]  "
                      f"å³: [{right_offset_safe[0]:+.3f}, {right_offset_safe[1]:+.3f}, {right_offset_safe[2]:+.3f}]", end='')
            
            # æ§åˆ¶é¢‘ç‡
            elapsed = time.time() - loop_start
            if elapsed < dt:
                time.sleep(dt - elapsed)
                
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
    finally:
        print("\né€€å‡ºæ§åˆ¶æ¨¡å¼...")
        robot.set_ub_manip_mode(2)
        print("âœ… Mode 2 (é€€å‡º)")
        time.sleep(2)
        
        robot.enter_damping()
        print("âœ… é˜»å°¼æ¨¡å¼")
        
        # æ¸…ç†
        img_shm.close()
        img_shm.unlink()
        print("ğŸ‘‹ é€€å‡ºå®Œæˆ")


if __name__ == "__main__":
    main()
